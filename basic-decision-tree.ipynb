{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"test_set = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"6446434b325cccb9f4fe482e196bf180ac0ab8c0"},"cell_type":"code","source":"train_set = pd.read_csv('../input/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e78f5e707b8dc0bec19210f43136ec2493e350db"},"cell_type":"code","source":"# data cleaning\nfull_data = [train_set, test_set]\n\nfor dataset in full_data:\n    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n    \nfor dataset in full_data:\n    dataset['IsAlone'] = 0\n    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n\nfor dataset in full_data:\n    age_avg = dataset['Age'].mean()\n    age_std = dataset['Age'].std()\n    age_null_count = dataset['Age'].isnull().sum()\n    age_null_random_list = np.random.randint(age_avg - age_std, age_avg + age_std, size=age_null_count)\n    dataset['Age'][np.isnan(dataset['Age'])] = age_null_random_list\n    dataset['Age'] = dataset['Age'].astype(int)\ntrain_set['CategoricalAge'] = pd.cut(train_set['Age'], 5)\n\nfor dataset in full_data:\n    dataset.loc[ dataset['Age'] <= 16, 'Age']  = 0\n    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n    dataset.loc[ dataset['Age'] > 64, 'Age'] = 4 ;\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e81934ac2c6d90bf623a80db1c8471cda983420f","collapsed":true},"cell_type":"code","source":"train_set = train_set.set_index('PassengerId')\ntest_set = test_set.set_index('PassengerId')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"948cc8fc5c05e4408792f5f595be5171f21df98c","scrolled":true,"collapsed":true},"cell_type":"code","source":"train_set['SexBinary'] = train_set['Sex'].apply(lambda x: 1 if x =='male' else 0)\ntrain_set['Family'] = train_set['SibSp'].apply(lambda x: 1 if x > 0 else 0)\ntrain_set['Survived'] = train_set.replace(to_replace=0,value=-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fa58a5abbdcd1980873206880b2bbb0e3d4a9192"},"cell_type":"code","source":"train_set.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"b9328341c466d993349112e9f7b749e87ffd58b0"},"cell_type":"code","source":"features = ['Age','Pclass','SexBinary','FamilySize','IsAlone']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9119d05861b1d6854614583c597d8a5379352204","collapsed":true},"cell_type":"code","source":"survivor = train_set[train_set['Survived'] == 1]\ndead = train_set[train_set['Survived'] == -1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"193531fd60848233362cd959bd81485a7109248a","collapsed":true},"cell_type":"code","source":"def intermediate_node_num_mistakes(labels_in_node):\n    survivor_ct = 0\n    dead_ct = 0\n    # Corner case: If labels_in_node is empty, return 0\n    if len(labels_in_node) == 0:\n        return 0\n    for label in labels_in_node:\n    # Count the number of 1's (safe loans)\n        if label == 1:\n            survivor_ct += 1\n    # Count the number of -1's (risky loans)\n        elif label == -1:\n            dead_ct += 1        \n    # Return the number of mistakes that the majority classifier makes.\n    return min(survivor_ct, dead_ct)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"9cbdd88c25770718e5c357a2b4cdb6441fa24025"},"cell_type":"code","source":"def best_splitting_feature(data, features, target):\n    \n    best_feature = None # Keep track of the best feature \n    best_error = 10     # Keep track of the best error so far \n    # Note: Since error is always <= 1, we should intialize it with something larger than 1.\n\n    # Convert to float to make sure error gets computed correctly.\n    num_data_points = float(len(data))  \n    \n    # Loop through each feature to consider splitting on that feature\n    for feature in features:\n        \n        # The left split will have all data points where the feature value is 0\n        left_split = data[data[feature] == 0]\n        \n        # The right split will have all data points where the feature value is 1\n        right_split =  data[data[feature] == 1]\n            \n        # Calculate the number of misclassified examples in the left split.\n        # Remember that we implemented a function for this! (It was called intermediate_node_num_mistakes)\n\n        left_mistakes = intermediate_node_num_mistakes(left_split[target])            \n\n        # Calculate the number of misclassified examples in the right split.\n\n        right_mistakes = intermediate_node_num_mistakes(right_split[target])  \n            \n        # Compute the classification error of this split.\n        # Error = (# of mistakes (left) + # of mistakes (right)) / (# of data points)\n\n        error = (left_mistakes+right_mistakes)/num_data_points\n\n        # If this is the best error we have found so far, store the feature as best_feature and the error as best_error\n\n        if error < best_error:\n            best_error = error\n            best_feature = feature\n    \n    return best_feature # Return the best feature we found","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6159b8f951ba0c57b9b84048b1fb24ddd49067a1","collapsed":true},"cell_type":"code","source":"def create_leaf(target_values):\n    \n    # Create a leaf node\n    leaf = {'splitting_feature' : None,\n            'left' : None,\n            'right' : None,\n            'is_leaf': True    }  \n    \n    # Count the number of data points that are +1 and -1 in this node.\n    num_ones = len(target_values[target_values == +1])\n    num_minus_ones = len(target_values[target_values == -1])\n    \n    # For the leaf node, set the prediction to be the majority class.\n    # Store the predicted class (1 or -1) in leaf['prediction']\n    \n    if num_ones > num_minus_ones:\n        leaf['prediction'] = +1          \n    else:\n        leaf['prediction'] = -1        \n        \n    # Return the leaf node        \n    return leaf ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5934cb43ad26fa5927502f213fbb807f65b520ba","collapsed":true},"cell_type":"code","source":"def decision_tree_create(data, features, target, current_depth = 0, max_depth = 10):\n    remaining_features = features[:] # Make a copy of the features.\n    \n    target_values = data[target]\n    print (\"--------------------------------------------------------------------\")\n    print (\"Subtree, depth = %s (%s data points).\" % (current_depth, len(target_values)))\n    \n\n    # Stopping condition 1\n    # (Check if there are mistakes at current node.\n    # Recall you wrote a function intermediate_node_num_mistakes to compute this.)\n    if intermediate_node_num_mistakes(target_values) == 0:  \n        print (\"Stopping condition 1 reached.\")     \n        # If not mistakes at current node, make current node a leaf node\n        return create_leaf(target_values)\n    \n    # Stopping condition 2 (check if there are remaining features to consider splitting on)\n    if remaining_features == []:  \n        print (\"Stopping condition 2 reached.\")    \n        # If there are no remaining features to consider, make current node a leaf node\n        return create_leaf(target_values)    \n    \n    # Additional stopping condition (limit tree depth)\n    if current_depth >= max_depth:  \n        print (\"Reached maximum depth. Stopping for now.\")\n        # If the max tree depth has been reached, make current node a leaf node\n        return create_leaf(target_values)\n\n    # Find the best splitting feature (recall the function best_splitting_feature implemented above)\n    \n    splitting_feature = best_splitting_feature(data, features, target)\n    \n    # Split on the best feature that we found. \n    left_split = data[data[splitting_feature] == 0]\n    right_split = data[data[splitting_feature] == 1]      \n    remaining_features.remove(splitting_feature)\n    print (\"Split on feature %s. (%s, %s)\" % (\n                      splitting_feature, len(left_split), len(right_split)))\n    \n    # Create a leaf node if the split is \"perfect\"\n    if len(left_split) == len(data):\n        print (\"Creating leaf node.\")\n        return create_leaf(left_split[target])\n    if len(right_split) == len(data):\n        print (\"Creating leaf node.\")\n        \n        return create_leaf(right_split[target])\n        \n    # Repeat (recurse) on left and right subtrees\n    left_tree = decision_tree_create(left_split, remaining_features, target, current_depth + 1, max_depth)        \n    \n    right_tree = decision_tree_create(right_split, remaining_features, target, current_depth + 1, max_depth)\n\n    return {'is_leaf'          : False, \n            'prediction'       : None,\n            'splitting_feature': splitting_feature,\n            'left'             : left_tree, \n            'right'            : right_tree}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"d7f28c3d386483c67062aded268d098f69a5c0a5"},"cell_type":"code","source":"def count_nodes(tree):\n    if tree['is_leaf']:\n        return 1\n    return 1 + count_nodes(tree['left']) + count_nodes(tree['right'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1ffba40c95fbe3274d65b29ccc049a809f715202"},"cell_type":"code","source":"titanic_decision_tree = decision_tree_create(train_set, features, 'Survived', max_depth = 5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"32c02585b6f2c77f81f6eb2916eb4ba0f97a8674"},"cell_type":"code","source":"def classify(tree, x, annotate = False):   \n    # if the node is a leaf node.\n    if tree['is_leaf']:\n        if annotate: \n            print (\"At leaf, predicting %s\" % tree['prediction'])\n        return tree['prediction'] \n    else:\n        # split on feature.\n        split_feature_value = x[tree['splitting_feature']]\n        if annotate: \n            print (\"Split on %s = %s\" % (tree['splitting_feature'], split_feature_value))\n        if split_feature_value == 0:\n            return classify(tree['left'], x, annotate)\n        else:\n            return classify(tree['right'], x, annotate)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3b8d48690ab02b4eb10074c9344d1ccfda82e83f","scrolled":true},"cell_type":"code","source":"print ('Predicted class: %s ' % classify(titanic_decision_tree, train_set.iloc[56]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cf278513cf2f544d1189da0379937e2e20bf073a"},"cell_type":"code","source":"test_set.iloc[56]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b77372121853f2583399e0bdaea6038b40d4c724","collapsed":true},"cell_type":"code","source":"test_set['SexBinary'] = test_set['Sex'].apply(lambda x: 1 if x =='male' else 0)\ntest_set['Family'] = test_set['SibSp'].apply(lambda x: 1 if x > 0 else 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4b50824d55229d4109850056b4bd03d22bc0728c"},"cell_type":"code","source":"test_set.fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1d5b35c5d80aa6410c16a822f357507ed03f10d7"},"cell_type":"code","source":"print ('Predicted class: %s ' % classify(titanic_decision_tree, test_set.iloc[56]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"071f840791604bc0fb8fe4e905979b40e8b27c2d","collapsed":true},"cell_type":"code","source":"def evaluate_classification_error(tree, data, target):\n    # Apply the classify(tree, x) to each row in your data\n    pred_temp = []\n    for i in range(len(data)):\n        pred_temp.append(classify(tree, data.iloc[i]))\n    data['prediction'] = pred_temp\n    \n    # Once you've made the predictions, calculate the classification error and return it\n    return 1.0 * sum(data['prediction'] != data[target])/len(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"31bfd29168a26bc8ef57e55e2b9abf4b29e65700"},"cell_type":"code","source":"xtrain, xtest = train_test_split(train_set, test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3ba7fd41cf58f91386fa57e61aa324bba735b249"},"cell_type":"code","source":"evaluate_classification_error(titanic_decision_tree, xtrain, 'Survived')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4cd9b0e23267341f58cc698e0c94dfcbfad0fe63","collapsed":true},"cell_type":"code","source":"submission = test_set.copy()\nsubmission = submission.fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1c7218b22b30f8dbaaf8006ebff7f31dd3d7e2d2","collapsed":true},"cell_type":"code","source":"submission['Survived'] = test_set.apply(lambda row: classify(titanic_decision_tree, row), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"98683b9b008e6e1809d2f1cb450237bcf0bb3535","collapsed":true},"cell_type":"code","source":"submission['Survived'] = submission['Survived'].replace(to_replace=-1,value=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"be83394a9340bd14ab223ebec9dc1a739b1687ad"},"cell_type":"code","source":"decision_submission = submission.reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f31019f8a054791f99dcafeb558d7f6e4ef5fc1d","collapsed":true},"cell_type":"code","source":"decision_submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ce84c442a16d5393720c31e2c5aca54cb7297e5d","collapsed":true},"cell_type":"code","source":"decision_submission[['PassengerId','Survived']].to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8b0d486da0a8ae8e31c4821952557eeee6f85bbb","collapsed":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"cd4bba7a6226114b83ed19772843c7357bb287c4"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2662f227b4b8df665cdb39def655d1fd98846b7e","collapsed":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"11730ad76859794f5d98f48799620d7d23c6bc01"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ba4112eaf58aa3ac62b0400c270efa74f5761d4d","collapsed":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"6460a422f3e4f48099cb3184f5ddc6ffd181a4e7"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"8d5faeba59ea4152cbeeafc35062e81d1f3c09b6"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"ed2766973eb2c219099491d850c92090b08b4b7a"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"64b040eb7ef4d6822f2be73abd5f4661a63b8a59"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f0c1d9382f46676439ee82001cf3a99dcf4be4e9","collapsed":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"56799f68f9858a919b01d191323e8f56936dcaf5","collapsed":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"876e3a44dddfa43692854a7c3cc35148d36b3f09","collapsed":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7113a5a7997fe894c5e10420804981bc0bc032d2","collapsed":true},"cell_type":"code","source":"\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"75eb2d75255e3a944e42c0a0ae235e56f7cbb38a","collapsed":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e8b4dd0c7a9c7a5df031ecb16c507ffe31e26b9e","collapsed":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"abc88630e890aadb9846ebd2c716140044d2aca5","collapsed":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"32414b901f56a8d0557e75e758ca45a5dfb1ffe7"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}